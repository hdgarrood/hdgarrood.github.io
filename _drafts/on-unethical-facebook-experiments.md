---
layout: post
title: On unethical Facebook experiments
---

A few thoughts on the recent furore regarding psychological experiments on
Facebook users, where the subjects were not aware that they were being
experimented on.

### Should we 'expect' Facebook to behave ethically?

It's worth noting that there are two subtly different definitions of the word
*expect*: to expect something can be to consider it likely: "We expect to make
a net gain from this event", but also to consider it reasonable; to seek
something with some (often moral) justification: "Attendees are expected to
abide by the code of conduct."

I agree that we should not consider it likely for Facebook to behave ethically.
However I think we *should* hold Facebook up to a high moral standard. If we
simply shrug, say "that's just how it is," and allow them to continue, then we
deserve everything we get.

Now that that is out of the way:

### Are these experiments surprising?

No&mdash;given Facebook's track record, it is clear that they do not care about
their users. Facebook's history is full of episodes of neglecting to respect
your privacy as a user: tracking you all over the web, [constant assault on
your ability to keep your information private][], and mobile apps requiring an
intrusive level of access to your phone (such as getting your contact list,
reading your SMS messages, or turning on your microphone or camera at any time
without confirmation). There's also the fact that algorithms rather than people
often decide whether users have broken the community standards and should be
blocked (which, needless to say, are hopelessly inadequate), and a completely
unbalanced approach to removing inappropriate content (breastfeeding pictures
are deemed unacceptable, while hate groups dedicated to praising murderers are
not).

### Does that make these revelations insignificant?

Of course not! Something about these experiments has upset a lot of people,
regardless of whether it would have done had they all been behaving perfectly
rationally. Reminder: behaving perfectly rationally is **not something humans
tend to do**.

![xkcd: Research Ethics](http://imgs.xkcd.com/comics/research_ethics.png)

It's true that now does seem an odd time to start being bothered about Facebook
manipulating news feeds; the xkcd comic points out the cognitive inconsistency
that many people have been guilty of (including me). But it's far more
interesting and useful to look at the issues that have been raised:

* What level of control over our emotions does Facebook have? What about other
  aspects of our behaviour? What about our ability to communicate with friends?
* What can we expect them to do, or not to do, with this control? Do we trust
  them with it?
* How do our priorities interact (or conflict) with theirs?

Here's some potential situations to think about.

Facebook could very well make an informed estimate of the political views of
large numbers of users based on the statuses they post, and the things they
like and comment on. Combine this with the fact that a recent feature allows
users to indicate to their friends that they have voted, in addition to showing
users that have not yet voted where their nearest polling stations are, and
that this feature, in the past, has increased turnout enough to sway an
election. Suppose that Facebook had some interest in the outcome of an election.
To what extent [could they manipulate it][]? To what extent might they?

Suppose, now, that some government has done a number of things that have
greatly upset their electorate. Large protests are being planned, which makes
this government uncomfortable. Could Facebook identify people who are the most
likely to persuade others to participate in protest action? If this government
approached Facebook and demanded that they manipulate these people, would they?
How could they do this? Might they boost posts that promote a sense of
hopelessness? Might posts calling people to action be quietly tucked away by
the mysterious and opaque news feed algorithm? Might accounts be banned based
on spurious evidence?

I hope my point is clear by this stage: regardless of whether Facebook might do
these things, being in a position where it is possible for them to do so is not
acceptable. We must not allow Facebook (or any other party) to have this level
of control over our lives. Facebook is [too important][] to be owned by
Facebook.

### Final thoughts

To those who [patronisingly look down][] upon everyone who is bothered about
this: please shut up. You are not helping. For the sake of self-indulgence, for
the opportunity to feel superior to people for a few moments, you are
reinforcing the status quo. If the situation deteriorates further, you will
partly have enabled it.

To those who wonder if I have an answer: I am convinced that we must [regain
control of our digital selves][]. The only way I see this happening is with
free (as in speech), open source software. Pay close attention to and support
initiatives like [ind.ie](https://ind.ie) (I plan to start contributing code
when I can). Consider a free operating system for your next computer (I
recommend Ubuntu). Educate yourself about the issue: watch [Digital Feudalism
and How to Avoid It][]. Consider deactivating Facebook or Google accounts.

[patronisingly look down]: http://www.theguardian.com/technology/2014/jul/06/we-shouldnt-expect-facebook-to-behave-ethically
[constant assault on your ability to keep your information private]: https://www.eff.org/deeplinks/2010/04/handy-facebook-english-translator
[could they manipulate it]: http://www.newrepublic.com/article/117878/information-fiduciary-solution-facebook-digital-gerrymandering
[too important]: http://blog.steveklabnik.com/posts/2011-07-24-twitter-is-to-important-to-be-owned-by-twitter
[regain control of our digital selves]: http://aralbalkan.com/notes/indie-data/
[Digital Feudalism and How to Avoid It]: https://www.youtube.com/watch?v=G1QCBzQ0aNc
